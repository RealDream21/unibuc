\def\timpInainteDeRay{37}
\def\timpDupaRay{18}

\chapter{Arhitectura aplicației}
\section{Împărțirea codului}
Codul este împărțit în 4 clase diferite. Ele au rolul de a forma un pipeline ce primește la intrare fișiere în format csv, împreună cu montura electrozilor și ca rezultat oferă obiecte în formatul librăriei MNE\cite{MNE}.
În total, pipeline-ul meu este format din 5 clase: EEGPipelineOptions, EEGSubjectPipeline, EEGDataLoader, EEGPreprocessor și EEGEpochedData. 

Prima dată, opțiunile de preprocesare și de formatare în epoci sunt setate utilizând EEGPipelineOptions. Acest obiect este trimis mai departe către EEGSubjectPipeline. Aici, este orchestrat restul pipeline-ului în felul următor: datele din format .csv sunt transformate în format .fif(compatibil cu MNE\cite{MNE}) utilizând EEGDataLoader. Datele în format .fif sunt transformate în date de forma mne.Raw(semnalul întreg, nesegmentat). Aici sunt totodată și preprocesate utilizând filtrul trece-bandă, ICA, interpolarea, și/sau, opțional, normalizare și scalare în intervalul [0, 1].  Ultimul pas îl reprezintă EEGEpochedData, unde semnalul Raw este segmentat în epoci. În funcție de opțiunile alese, aici poate fi aplicat și algoritmul de AutoReject\cite{AutoReject} pentru a elimina de epocile corupte. Totodată, în această clasă este situată și funcția de extragere a setului de date, împreună cu labelul acestuia.


\section{Alte librării folosite}
\subsection{Optimizarea încărcării datelor folosind Ray}
Pentru a încărca eficient cei 26 de participanți am utilizat librăria Ray\cite{Ray}. Ray este o librărie specializată în paralelizarea programelor Python, având ca scop principal programele din domeniul de Machine Learning. Modul de paralelizare a constat prin decorarea functiilor de încarcare a datelor cu @ray.remote și așteptarea rezultatului cu ray.get. Timpul de încărcare a datelor participanților a fost redus de la $\timpInainteDeRay$ secunde la $\timpDupaRay$ secunde. Paralelizarea folosind Ray poate fi observată în figura \ref{fig:paralelizare_ray} din Appendix. Această scădere a avut un impact mai accentuat în momentul căutării hiperparametrilor, am putut astfel să dublez totalul parametrilor căutați în același interval de timp.

%După cum putem observa în figura \ref{fig:load_calculator}, paralelizarea a funcționat, ducând procesorul calculatorului la 100\%.

\subsection{Căutarea hiperparametrilor folosind Optuna}
Optuna\cite{optuna_2019} este o librărie ce se ocupă de căutarea hiperparametrilor. Parametrii căutați au fost cei legați de EEGPipelineOptions. Scopul a fost să înțeleg ce preprocesări trebuiesc executate pentru performanță maximă. Pentru a rula pipeline-ul meu folosind optuna, am definit o funcție obiectiv, și anume f1 score-ul obținut în urma validării încrucișate. Mai departe, am setat hiperparametrii pe care ar trebui să-i caute librăria. Am salvat cei mai buni parametrii în funcție de scorul F1. Astfel, am putut să caut sistematic cei mai buni hiperparametrii de preprocesare. Întreg procesul poate fi văzut în detaliu în figura \ref{fig:optuna_search} din Appendix.
